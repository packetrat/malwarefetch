#!/usr/bin/env python3
import requests, pandas, re, sys, getopt, os
from urllib.parse import urlparse
import requests

inputfile = input("Enter filename containing URIs to be checked: ")  
dataset = pandas.read_csv(inputfile)
# we're pulling URLs from an existing CSV. The URLs are in a column named "url". #
o = inputfile + '_results.csv'
# we will be writing another CSV with the filenames that are downloaded to match them up to the URLS for later analysis
opf = open( o, 'w')
for index, row in dataset.iterrows():
    url = str(row['url'])
    try:
        r = requests.get(url, allow_redirects=True)
    except OSError as e:
        print(url + " has failed")
    filename = os.path.basename(url)
    if os.path.exists(filename):
        filename = str(index) + filename
        #This is to prevent duplicate filenames. It's a band-aid, but it's less complicated than iterating through duplicate files to append the right number.
    try:
        open(filename, 'wb').write(r.content)
    except OSError as e:
        print("no file to write for " + url)
        filename = "no file"
    opf.write(u"{},{}\n".format(url, filename))
